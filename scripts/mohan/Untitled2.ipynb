{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "353c9722",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install nltk\n",
    "import nltk\n",
    "nltk.download('all')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68ed6315",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-26 01:44:34.962235: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-03-26 01:44:34.962311: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import re\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from pickle import dump\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7d51cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "\n",
    "BUCKET_NAME = 'quotes_for_posts_783'\n",
    "\n",
    "BUCKET_TRAIN_DATA_PATH = 'raw_data/image_dataset/image_dataset'\n",
    "BUCKET_TRAIN_DATA_PATH_1= 'raw_data/image_dataset/df_images_0.csv'\n",
    "glove_path = 'raw_data/image_dataset/glove.6B.300d.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "331411a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_blob(bucket_name, source_blob_name, destination_file_name):\n",
    "    \"\"\"Downloads a blob from the bucket.\"\"\"\n",
    "    client = storage.Client()\n",
    "    bucket = client.bucket(bucket_name)\n",
    "    blob = bucket.blob(source_blob_name)\n",
    "    blob.download_to_filename(destination_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bae3bed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(directory, df_im_0):\n",
    "    \n",
    "    model = VGG16()\n",
    "    \n",
    "    #remove last layer\n",
    "    model.layers.pop()\n",
    "    \n",
    "    model = Model(inputs = model.inputs , outputs = model.layers[-1].output)\n",
    "    \n",
    "    print(model.summary())\n",
    "    \n",
    "    features = dict()\n",
    "    \n",
    "    for name in listdir(directory):\n",
    "        \n",
    "        # load and image\n",
    "        \n",
    "    \n",
    "        images = list(df_im_0)\n",
    "\n",
    "        for i in images:\n",
    "            \n",
    "            filename = directory + '/' + name\n",
    "\n",
    "            #imagePath =f'{directory} /{i}.jpg'\n",
    "\n",
    "            #download_blob(BUCKET_NAME, imagePath, 'temp.jpg')\n",
    "\n",
    "            #image = load_img('temp.jpg' , target_size=(224 , 224))\n",
    "\n",
    "            image = load_img(filename , target_size=(224 , 224))\n",
    "\n",
    "            image = img_to_array(image)\n",
    "\n",
    "            image = image.reshape((1 , image.shape[0] , image.shape[1] ,image.shape[2]))\n",
    "\n",
    "            image = preprocess_input(image)\n",
    "\n",
    "            feature = model.predict(image , verbose = 0)\n",
    "\n",
    "            # get image id\n",
    "            image_id = name.split(\".\")[0]\n",
    "\n",
    "            # store features\n",
    "            features[image_id] = feature\n",
    "\n",
    "            print(name)\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6fd73a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_im_0 = pd.read_csv(f'gs://{BUCKET_NAME}/{BUCKET_TRAIN_DATA_PATH_1}')\n",
    "df_im_0 = df_im_0.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf46e9b2",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3876652419</td>\n",
       "      <td>A guy in a black shirt is looking to catch a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3876652419</td>\n",
       "      <td>Young man in blue shirt throwing a watermelon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3876652419</td>\n",
       "      <td>Three young boys are engaged in a game of do ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3876652419</td>\n",
       "      <td>Three teenagers unloading a truck with waterm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3876652419</td>\n",
       "      <td>Three young boys tossing a watermelon .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>2778313163</td>\n",
       "      <td>A woman in a blue t-shirt and jeans is sweepi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>2778313163</td>\n",
       "      <td>A young woman with a black shirt and jeans sw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>2778313163</td>\n",
       "      <td>A young woman sweeping with a straw broom .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>2778313163</td>\n",
       "      <td>a woman sweeps the foundation of a house .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>2778313163</td>\n",
       "      <td>Individuals are building a house .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    image_name                                           comments\n",
       "0   3876652419   A guy in a black shirt is looking to catch a ...\n",
       "1   3876652419   Young man in blue shirt throwing a watermelon...\n",
       "2   3876652419   Three young boys are engaged in a game of do ...\n",
       "3   3876652419   Three teenagers unloading a truck with waterm...\n",
       "4   3876652419            Three young boys tossing a watermelon .\n",
       "..         ...                                                ...\n",
       "95  2778313163   A woman in a blue t-shirt and jeans is sweepi...\n",
       "96  2778313163   A young woman with a black shirt and jeans sw...\n",
       "97  2778313163        A young woman sweeping with a straw broom .\n",
       "98  2778313163         a woman sweeps the foundation of a house .\n",
       "99  2778313163                 Individuals are building a house .\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_im_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80ea979a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_im_0['image_name'] = df_im_0['image_name'].astype('str') + '.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "16ef65fe",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['3876652419.jpg', '2147870343.jpg', '3071144200.jpg',\n",
       "       '2521062020.jpg', '4477602852.jpg', '5590283636.jpg',\n",
       "       '96113759.jpg', '3533660418.jpg', '3041642723.jpg',\n",
       "       '3260768565.jpg', '4890769146.jpg', '3264832994.jpg',\n",
       "       '2289751916.jpg', '2987576188.jpg', '2469827608.jpg',\n",
       "       '3078402009.jpg', '2174648405.jpg', '289387198.jpg',\n",
       "       '221063801.jpg', '2778313163.jpg'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.unique(df_im_0['image_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "707be500",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-26 11:31:07.326234: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-03-26 11:31:07.521988: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-03-26 11:31:07.522208: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2022-03-26 11:31:07.522290: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2022-03-26 11:31:07.522364: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2022-03-26 11:31:07.522600: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2022-03-26 11:31:07.522717: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2022-03-26 11:31:07.523000: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2022-03-26 11:31:07.523114: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2022-03-26 11:31:07.523132: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-03-26 11:31:07.535504: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25088)             0         \n",
      "                                                                 \n",
      " fc1 (Dense)                 (None, 4096)              102764544 \n",
      "                                                                 \n",
      " fc2 (Dense)                 (None, 4096)              16781312  \n",
      "                                                                 \n",
      " predictions (Dense)         (None, 1000)              4097000   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 138,357,544\n",
      "Trainable params: 138,357,544\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "289387198.jpg\n",
      "289387198.jpg\n",
      "3533660418.jpg\n",
      "3533660418.jpg\n",
      "2147870343.jpg\n",
      "2147870343.jpg\n",
      "4890769146.jpg\n",
      "4890769146.jpg\n",
      "5590283636.jpg\n",
      "5590283636.jpg\n",
      "2469827608.jpg\n",
      "2469827608.jpg\n",
      "2174648405.jpg\n",
      "2174648405.jpg\n",
      "3071144200.jpg\n",
      "3071144200.jpg\n",
      "3041642723.jpg\n",
      "3041642723.jpg\n",
      "2521062020.jpg\n",
      "2521062020.jpg\n",
      "96113759.jpg\n",
      "96113759.jpg\n",
      "3260768565.jpg\n",
      "3260768565.jpg\n",
      "2289751916.jpg\n",
      "2289751916.jpg\n",
      "2778313163.jpg\n",
      "2778313163.jpg\n",
      "221063801.jpg\n",
      "221063801.jpg\n",
      "3078402009.jpg\n",
      "3078402009.jpg\n",
      "4477602852.jpg\n",
      "4477602852.jpg\n",
      "2987576188.jpg\n",
      "2987576188.jpg\n",
      "3264832994.jpg\n",
      "3264832994.jpg\n",
      "3876652419.jpg\n",
      "3876652419.jpg\n",
      "extracted features : 20\n"
     ]
    }
   ],
   "source": [
    "from os import listdir\n",
    "#directory = 'gs://{BUCKET_NAME}/{BUCKET_TRAIN_DATA_PATH}'\n",
    "directory = '../../raw_data/image_dataset/small_data'\n",
    "features = extract_features(directory, df_im_0)\n",
    "print('extracted features :',len(features))\n",
    "dump(features , open('features.pkl' , 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "789e2114",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemma = WordNetLemmatizer()\n",
    "\n",
    "def load_decriptions(doc):\n",
    "    mapping = dict()\n",
    "    \n",
    "    for i in range(len(doc)):\n",
    "        image_id = doc['image_name'][i]\n",
    "        image_desc = doc['comments'][i]\n",
    "        \n",
    "        if image_id not in mapping:\n",
    "            mapping[image_id] = list()\n",
    "        \n",
    "        mapping[image_id].append(image_desc)\n",
    "        \n",
    "    return mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d0af5812",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(desc):\n",
    "    \n",
    "    # clean punctuation\n",
    "    desc = re.sub(r'[^\\w\\s]' ,'', desc)\n",
    "    \n",
    "    # tokenize the words\n",
    "    desc = desc.split()\n",
    "    \n",
    "    # convert to lower case\n",
    "    desc = [token.lower() for token in desc]\n",
    "    \n",
    "    # lemmatization\n",
    "    desc = [lemma.lemmatize(token) for token in desc]\n",
    "    \n",
    "    # remove numerical values\n",
    "    desc = [token for token in desc if token.isalpha()]\n",
    "    \n",
    "    # join whole token\n",
    "    desc = ' '.join(desc)\n",
    "    \n",
    "    return desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "38afbf13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert loaded descriptions into vocablury\n",
    "def to_vocabluary(descriptions):\n",
    "    all_desc = set()\n",
    "    \n",
    "    for key in descriptions.keys():\n",
    "        [all_desc.update(d.split()) for d in descriptions[key]]\n",
    "        \n",
    "    return all_desc\n",
    "\n",
    "def save_descriptions(descriptions , filename):\n",
    "    lines = list()\n",
    "    \n",
    "    for key , desc_list in descriptions.items():\n",
    "        for desc in desc_list:\n",
    "            lines.append(key +' '+ desc)\n",
    "            \n",
    "    data = '\\n'.join(lines)\n",
    "    file = open(filename , 'w')\n",
    "    file.write(data)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6deebd8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "download_blob(BUCKET_NAME, glove_path, 'temp.txt')\n",
    "glove = open('temp.txt', encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7c8d5952",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_im_0['comments'] = df_im_0['comments'].apply(lambda x : clean_text(str(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ab35bf96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3876652419.jpg</td>\n",
       "      <td>a guy in a black shirt is looking to catch a w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3876652419.jpg</td>\n",
       "      <td>young man in blue shirt throwing a watermelon ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3876652419.jpg</td>\n",
       "      <td>three young boy are engaged in a game of do nt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3876652419.jpg</td>\n",
       "      <td>three teenager unloading a truck with watermelon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3876652419.jpg</td>\n",
       "      <td>three young boy tossing a watermelon</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       image_name                                           comments\n",
       "0  3876652419.jpg  a guy in a black shirt is looking to catch a w...\n",
       "1  3876652419.jpg  young man in blue shirt throwing a watermelon ...\n",
       "2  3876652419.jpg  three young boy are engaged in a game of do nt...\n",
       "3  3876652419.jpg   three teenager unloading a truck with watermelon\n",
       "4  3876652419.jpg               three young boy tossing a watermelon"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_im_0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f6d70c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_map = load_decriptions(df_im_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "36236b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = to_vocabluary(desc_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d737c534",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "349"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "77969bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_descriptions(desc_map , 'descriptions.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3de5b9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pickle import load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f20781e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the doc\n",
    "def load_doc(filename):\n",
    "    file = open(filename , 'r')\n",
    "    text = file.read()\n",
    "    file.close()\n",
    "    return text\n",
    "\n",
    "# this function is used for to get train image description from our dataset\n",
    "\n",
    "def load_clean_descriptions(filename , dataset):\n",
    "    doc = load_doc(filename)\n",
    "    descriptions = dict()\n",
    "    \n",
    "    for line in doc.split('\\n'):\n",
    "        tokens = line.split()\n",
    "        image_name , image_desc = tokens[0] , tokens[1:]\n",
    "        \n",
    "        if image_name in dataset:\n",
    "            \n",
    "            if image_name not in descriptions:\n",
    "                descriptions[image_name] = list()\n",
    "            \n",
    "            # we add two tage at start and at end of the descitpion to identify to start and \n",
    "            # end of desc.\n",
    "            desc = 'startseq '+ ' '.join(image_desc)+ ' endseq'\n",
    "            descriptions[image_name].append(desc)\n",
    "            \n",
    "    return descriptions\n",
    "\n",
    "\n",
    "# laod photo features\n",
    "def load_photo_features(filename , dataset):\n",
    "    all_features = load(open(filename,'rb'))\n",
    "    features = {k+'.jpg' : all_features[k] for k in dataset}\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cc115d39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of train image 20\n"
     ]
    }
   ],
   "source": [
    "train = set(df_im_0['image_name'])\n",
    "print('len of train image',len(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d5e6f354",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of train descriptions 20\n"
     ]
    }
   ],
   "source": [
    "train_descriptions = load_clean_descriptions('descriptions.txt' , train)\n",
    "print('len of train descriptions' , len(train_descriptions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6a50c2e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "photos train : 20\n"
     ]
    }
   ],
   "source": [
    "train = pd.DataFrame(train)\n",
    "train2 = train[0].apply(lambda x : x.replace('.jpg' , ''))\n",
    "train_features = load_photo_features('features.pkl' , train2)\n",
    "print('photos train :',len(train_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4baf103f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4d22fae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def to_lines(descriptions):\n",
    "    all_desc = list()\n",
    "    for key in descriptions.keys():\n",
    "        [all_desc.append(d) for d in descriptions[key]]\n",
    "        \n",
    "    return all_desc\n",
    "\n",
    "# fit tokenizer on descriptions\n",
    "def create_tokenizer(descriptions):\n",
    "    lines = to_lines(descriptions)\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(lines)\n",
    "    return tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cbe8dc1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab size 352\n"
     ]
    }
   ],
   "source": [
    "tokenizer = create_tokenizer(train_descriptions)\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "print('vocab size' , vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "69f8aa20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras.utils in /home/mohanakrishnan/.pyenv/versions/3.8.12/envs/quotes_for_posts_783/lib/python3.8/site-packages (1.0.13)\r\n",
      "Requirement already satisfied: Keras>=2.1.5 in /home/mohanakrishnan/.pyenv/versions/3.8.12/envs/quotes_for_posts_783/lib/python3.8/site-packages (from keras.utils) (2.8.0)\r\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "391888a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the length with most words\n",
    "def max_length(descriptions):\n",
    "    lines = to_lines(descriptions)\n",
    "    return max([len(line.split())for line in lines])\n",
    "    \n",
    "# create sequences of images,input sequences and output sequences\n",
    "def create_sequences(tokenizer , max_length , desc_list , photo):\n",
    "    X1 , X2 , y = list() , list() , list()\n",
    "    \n",
    "    for desc in desc_list:\n",
    "        # convert words to number value\n",
    "        seq = tokenizer.texts_to_sequences([desc])[0]\n",
    "        \n",
    "        for i in range(1, len(seq)):\n",
    "            \n",
    "            in_seq , output_seq = seq[:i] , seq[i]\n",
    "            in_seq = pad_sequences([in_seq] , maxlen = max_length)[0]\n",
    "            output_seq = to_categorical([output_seq] , num_classes = vocab_size)[0]\n",
    "            \n",
    "            X1.append(photo)\n",
    "            X2.append(in_seq)\n",
    "            y.append(output_seq)\n",
    "            \n",
    "    return np.array(X1) , np.array(X2) , np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f0f210b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input , Dense , LSTM , Embedding , Dropout\n",
    "from keras.layers.merge import add\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fc3b2919",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_Model(vocab_size , max_length):\n",
    "    \n",
    "    # feature extractor model\n",
    "    inputs1 = Input(shape=(4096 , ))\n",
    "    fe1 = Dropout(0.5)(inputs1)\n",
    "    fe2 = Dense(512 , activation='relu')(fe1)\n",
    "    fe3 = Dense(256 , activation = 'relu')(fe2)\n",
    "    \n",
    "    # sequence model\n",
    "    inputs2 = Input(shape=(max_length,))\n",
    "    se1 = Embedding(vocab_size,512,mask_zero=True )(inputs2) # mask_zero = ignore padding\n",
    "    se2 = Dropout(0.5)(se1)\n",
    "    se3 = LSTM(512 , return_sequences=True)(se2)\n",
    "    se4 = Dropout(0.5)(se3)\n",
    "    se5 = LSTM(256)(se4)\n",
    "    \n",
    "    \n",
    "    #decoder Model\n",
    "    decoder1 = add([fe3 , se5])\n",
    "    decoder2 = Dense(256 , activation='relu')(decoder1)\n",
    "    decoder3 = Dense(512 , activation='relu')(decoder2)\n",
    "    outputs = Dense(vocab_size , activation='softmax')(decoder3)\n",
    "    \n",
    "    # combine both image and text\n",
    "    model = Model([inputs1 , inputs2] , outputs)\n",
    "    model.compile(loss='categorical_crossentropy' , optimizer = 'adam')\n",
    "    \n",
    "    # summary\n",
    "    print(model.summary())\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4cdeb606",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(descriptions , photos , tokenizer , max_length):\n",
    "    while 1:\n",
    "        for key , desc_list in descriptions.items():\n",
    "            photo = photos[key][0]\n",
    "            in_img , in_seq , out_seq = create_sequences(tokenizer , max_length , desc_list , photo)\n",
    "            \n",
    "            yield[[in_img , in_seq] , out_seq]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0a69a813",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len : 20\n",
      "Descriptions : 20\n",
      "photos train : 20\n",
      "Vocabulary size : 352\n",
      "Description max length : 26\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('len :', len(train))\n",
    "print('Descriptions :',len(train_descriptions))\n",
    "print('photos train :',len(train_features))\n",
    "print('Vocabulary size :',vocab_size)\n",
    "max_len = max_length(train_descriptions)\n",
    "print('Description max length :', max_len)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c2ff954b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a219b4a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)           [(None, 26)]         0           []                               \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, 26, 512)      180224      ['input_3[0][0]']                \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 4096)]       0           []                               \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 26, 512)      0           ['embedding[0][0]']              \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 4096)         0           ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " lstm (LSTM)                    (None, 26, 512)      2099200     ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 512)          2097664     ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 26, 512)      0           ['lstm[0][0]']                   \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 256)          131328      ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)                  (None, 256)          787456      ['dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 256)          0           ['dense_1[0][0]',                \n",
      "                                                                  'lstm_1[0][0]']                 \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 256)          65792       ['add[0][0]']                    \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 512)          131584      ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 352)          180576      ['dense_3[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 5,673,824\n",
      "Trainable params: 5,673,824\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1508/2303626749.py:8: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  model.fit_generator(generator , epochs = 1 , steps_per_epoch = steps , verbose = 1)\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node 'model_1/dense/Relu' defined at (most recent call last):\n    File \"/home/mohanakrishnan/.pyenv/versions/3.8.12/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/home/mohanakrishnan/.pyenv/versions/3.8.12/lib/python3.8/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/home/mohanakrishnan/.pyenv/versions/3.8.12/envs/quotes_for_posts_783/lib/python3.8/site-packages/ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"/home/mohanakrishnan/.pyenv/versions/3.8.12/envs/quotes_for_posts_783/lib/python3.8/site-packages/traitlets/config/application.py\", line 846, in launch_instance\n      app.start()\n    File \"/home/mohanakrishnan/.pyenv/versions/3.8.12/envs/quotes_for_posts_783/lib/python3.8/site-packages/ipykernel/kernelapp.py\", line 677, in start\n      self.io_loop.start()\n    File \"/home/mohanakrishnan/.pyenv/versions/3.8.12/envs/quotes_for_posts_783/lib/python3.8/site-packages/tornado/platform/asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"/home/mohanakrishnan/.pyenv/versions/3.8.12/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n      self._run_once()\n    File \"/home/mohanakrishnan/.pyenv/versions/3.8.12/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n      handle._run()\n    File \"/home/mohanakrishnan/.pyenv/versions/3.8.12/lib/python3.8/asyncio/events.py\", line 81, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/mohanakrishnan/.pyenv/versions/3.8.12/envs/quotes_for_posts_783/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 471, in dispatch_queue\n      await self.process_one()\n    File \"/home/mohanakrishnan/.pyenv/versions/3.8.12/envs/quotes_for_posts_783/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 460, in process_one\n      await dispatch(*args)\n    File \"/home/mohanakrishnan/.pyenv/versions/3.8.12/envs/quotes_for_posts_783/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 367, in dispatch_shell\n      await result\n    File \"/home/mohanakrishnan/.pyenv/versions/3.8.12/envs/quotes_for_posts_783/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 662, in execute_request\n      reply_content = await reply_content\n    File \"/home/mohanakrishnan/.pyenv/versions/3.8.12/envs/quotes_for_posts_783/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 360, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"/home/mohanakrishnan/.pyenv/versions/3.8.12/envs/quotes_for_posts_783/lib/python3.8/site-packages/ipykernel/zmqshell.py\", line 532, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/home/mohanakrishnan/.pyenv/versions/3.8.12/envs/quotes_for_posts_783/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2768, in run_cell\n      result = self._run_cell(\n    File \"/home/mohanakrishnan/.pyenv/versions/3.8.12/envs/quotes_for_posts_783/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2814, in _run_cell\n      return runner(coro)\n    File \"/home/mohanakrishnan/.pyenv/versions/3.8.12/envs/quotes_for_posts_783/lib/python3.8/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/mohanakrishnan/.pyenv/versions/3.8.12/envs/quotes_for_posts_783/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3012, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/home/mohanakrishnan/.pyenv/versions/3.8.12/envs/quotes_for_posts_783/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3191, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/home/mohanakrishnan/.pyenv/versions/3.8.12/envs/quotes_for_posts_783/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3251, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_1508/2303626749.py\", line 8, in <module>\n      model.fit_generator(generator , epochs = 1 , steps_per_epoch = steps , verbose = 1)\n    File \"/home/mohanakrishnan/.pyenv/versions/3.8.12/envs/quotes_for_posts_783/lib/python3.8/site-packages/keras/engine/training.py\", line 2209, in fit_generator\n      return self.fit(\n    File \"/home/mohanakrishnan/.pyenv/versions/3.8.12/envs/quotes_for_posts_783/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/mohanakrishnan/.pyenv/versions/3.8.12/envs/quotes_for_posts_783/lib/python3.8/site-packages/keras/engine/training.py\", line 1384, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/home/mohanakrishnan/.pyenv/versions/3.8.12/envs/quotes_for_posts_783/lib/python3.8/site-packages/keras/engine/training.py\", line 1021, in train_function\n      return step_function(self, iterator)\n    File \"/home/mohanakrishnan/.pyenv/versions/3.8.12/envs/quotes_for_posts_783/lib/python3.8/site-packages/keras/engine/training.py\", line 1010, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/mohanakrishnan/.pyenv/versions/3.8.12/envs/quotes_for_posts_783/lib/python3.8/site-packages/keras/engine/training.py\", line 1000, in run_step\n      outputs = model.train_step(data)\n    File \"/home/mohanakrishnan/.pyenv/versions/3.8.12/envs/quotes_for_posts_783/lib/python3.8/site-packages/keras/engine/training.py\", line 859, in train_step\n      y_pred = self(x, training=True)\n    File \"/home/mohanakrishnan/.pyenv/versions/3.8.12/envs/quotes_for_posts_783/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/mohanakrishnan/.pyenv/versions/3.8.12/envs/quotes_for_posts_783/lib/python3.8/site-packages/keras/engine/base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/mohanakrishnan/.pyenv/versions/3.8.12/envs/quotes_for_posts_783/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/mohanakrishnan/.pyenv/versions/3.8.12/envs/quotes_for_posts_783/lib/python3.8/site-packages/keras/engine/functional.py\", line 451, in call\n      return self._run_internal_graph(\n    File \"/home/mohanakrishnan/.pyenv/versions/3.8.12/envs/quotes_for_posts_783/lib/python3.8/site-packages/keras/engine/functional.py\", line 589, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/home/mohanakrishnan/.pyenv/versions/3.8.12/envs/quotes_for_posts_783/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/mohanakrishnan/.pyenv/versions/3.8.12/envs/quotes_for_posts_783/lib/python3.8/site-packages/keras/engine/base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/mohanakrishnan/.pyenv/versions/3.8.12/envs/quotes_for_posts_783/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/mohanakrishnan/.pyenv/versions/3.8.12/envs/quotes_for_posts_783/lib/python3.8/site-packages/keras/layers/core/dense.py\", line 233, in call\n      outputs = self.activation(outputs)\n    File \"/home/mohanakrishnan/.pyenv/versions/3.8.12/envs/quotes_for_posts_783/lib/python3.8/site-packages/keras/activations.py\", line 311, in relu\n      return backend.relu(x, alpha=alpha, max_value=max_value, threshold=threshold)\n    File \"/home/mohanakrishnan/.pyenv/versions/3.8.12/envs/quotes_for_posts_783/lib/python3.8/site-packages/keras/backend.py\", line 4956, in relu\n      x = tf.nn.relu(x)\nNode: 'model_1/dense/Relu'\nMatrix size-incompatible: In[0]: [65,1000], In[1]: [4096,512]\n\t [[{{node model_1/dense/Relu}}]] [Op:__inference_train_function_17352]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Input \u001b[0;32mIn [37]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[1;32m      6\u001b[0m     generator \u001b[38;5;241m=\u001b[39m data_generator(train_descriptions , train_features , tokenizer , max_len)\n\u001b[0;32m----> 8\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msteps\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m     model\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.h5\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/envs/quotes_for_posts_783/lib/python3.8/site-packages/keras/engine/training.py:2209\u001b[0m, in \u001b[0;36mModel.fit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2198\u001b[0m \u001b[38;5;124;03m\"\"\"Fits the model on data yielded batch-by-batch by a Python generator.\u001b[39;00m\n\u001b[1;32m   2199\u001b[0m \n\u001b[1;32m   2200\u001b[0m \u001b[38;5;124;03mDEPRECATED:\u001b[39;00m\n\u001b[1;32m   2201\u001b[0m \u001b[38;5;124;03m  `Model.fit` now supports generators, so there is no longer any need to use\u001b[39;00m\n\u001b[1;32m   2202\u001b[0m \u001b[38;5;124;03m  this endpoint.\u001b[39;00m\n\u001b[1;32m   2203\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2204\u001b[0m warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   2205\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`Model.fit_generator` is deprecated and \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   2206\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwill be removed in a future version. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   2207\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPlease use `Model.fit`, which supports generators.\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   2208\u001b[0m     stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m-> 2209\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2210\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2211\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2212\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2213\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2214\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2215\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2216\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2217\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_freq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2218\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2219\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2220\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2221\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2222\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2223\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial_epoch\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/envs/quotes_for_posts_783/lib/python3.8/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/envs/quotes_for_posts_783/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node 'model_1/dense/Relu' defined at (most recent call last):\n    File \"/home/mohanakrishnan/.pyenv/versions/3.8.12/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/home/mohanakrishnan/.pyenv/versions/3.8.12/lib/python3.8/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/home/mohanakrishnan/.pyenv/versions/3.8.12/envs/quotes_for_posts_783/lib/python3.8/site-packages/ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"/home/mohanakrishnan/.pyenv/versions/3.8.12/envs/quotes_for_posts_783/lib/python3.8/site-packages/traitlets/config/application.py\", line 846, in launch_instance\n      app.start()\n    File \"/home/mohanakrishnan/.pyenv/versions/3.8.12/envs/quotes_for_posts_783/lib/python3.8/site-packages/ipykernel/kernelapp.py\", line 677, in start\n      self.io_loop.start()\n    File \"/home/mohanakrishnan/.pyenv/versions/3.8.12/envs/quotes_for_posts_783/lib/python3.8/site-packages/tornado/platform/asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"/home/mohanakrishnan/.pyenv/versions/3.8.12/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n      self._run_once()\n    File \"/home/mohanakrishnan/.pyenv/versions/3.8.12/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n      handle._run()\n    File \"/home/mohanakrishnan/.pyenv/versions/3.8.12/lib/python3.8/asyncio/events.py\", line 81, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/mohanakrishnan/.pyenv/versions/3.8.12/envs/quotes_for_posts_783/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 471, in dispatch_queue\n      await self.process_one()\n    File \"/home/mohanakrishnan/.pyenv/versions/3.8.12/envs/quotes_for_posts_783/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 460, in process_one\n      await dispatch(*args)\n    File \"/home/mohanakrishnan/.pyenv/versions/3.8.12/envs/quotes_for_posts_783/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 367, in dispatch_shell\n      await result\n    File \"/home/mohanakrishnan/.pyenv/versions/3.8.12/envs/quotes_for_posts_783/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 662, in execute_request\n      reply_content = await reply_content\n    File \"/home/mohanakrishnan/.pyenv/versions/3.8.12/envs/quotes_for_posts_783/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 360, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"/home/mohanakrishnan/.pyenv/versions/3.8.12/envs/quotes_for_posts_783/lib/python3.8/site-packages/ipykernel/zmqshell.py\", line 532, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/home/mohanakrishnan/.pyenv/versions/3.8.12/envs/quotes_for_posts_783/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2768, in run_cell\n      result = self._run_cell(\n    File \"/home/mohanakrishnan/.pyenv/versions/3.8.12/envs/quotes_for_posts_783/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2814, in _run_cell\n      return runner(coro)\n    File \"/home/mohanakrishnan/.pyenv/versions/3.8.12/envs/quotes_for_posts_783/lib/python3.8/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/mohanakrishnan/.pyenv/versions/3.8.12/envs/quotes_for_posts_783/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3012, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/home/mohanakrishnan/.pyenv/versions/3.8.12/envs/quotes_for_posts_783/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3191, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/home/mohanakrishnan/.pyenv/versions/3.8.12/envs/quotes_for_posts_783/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3251, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_1508/2303626749.py\", line 8, in <module>\n      model.fit_generator(generator , epochs = 1 , steps_per_epoch = steps , verbose = 1)\n    File \"/home/mohanakrishnan/.pyenv/versions/3.8.12/envs/quotes_for_posts_783/lib/python3.8/site-packages/keras/engine/training.py\", line 2209, in fit_generator\n      return self.fit(\n    File \"/home/mohanakrishnan/.pyenv/versions/3.8.12/envs/quotes_for_posts_783/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/mohanakrishnan/.pyenv/versions/3.8.12/envs/quotes_for_posts_783/lib/python3.8/site-packages/keras/engine/training.py\", line 1384, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/home/mohanakrishnan/.pyenv/versions/3.8.12/envs/quotes_for_posts_783/lib/python3.8/site-packages/keras/engine/training.py\", line 1021, in train_function\n      return step_function(self, iterator)\n    File \"/home/mohanakrishnan/.pyenv/versions/3.8.12/envs/quotes_for_posts_783/lib/python3.8/site-packages/keras/engine/training.py\", line 1010, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/mohanakrishnan/.pyenv/versions/3.8.12/envs/quotes_for_posts_783/lib/python3.8/site-packages/keras/engine/training.py\", line 1000, in run_step\n      outputs = model.train_step(data)\n    File \"/home/mohanakrishnan/.pyenv/versions/3.8.12/envs/quotes_for_posts_783/lib/python3.8/site-packages/keras/engine/training.py\", line 859, in train_step\n      y_pred = self(x, training=True)\n    File \"/home/mohanakrishnan/.pyenv/versions/3.8.12/envs/quotes_for_posts_783/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/mohanakrishnan/.pyenv/versions/3.8.12/envs/quotes_for_posts_783/lib/python3.8/site-packages/keras/engine/base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/mohanakrishnan/.pyenv/versions/3.8.12/envs/quotes_for_posts_783/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/mohanakrishnan/.pyenv/versions/3.8.12/envs/quotes_for_posts_783/lib/python3.8/site-packages/keras/engine/functional.py\", line 451, in call\n      return self._run_internal_graph(\n    File \"/home/mohanakrishnan/.pyenv/versions/3.8.12/envs/quotes_for_posts_783/lib/python3.8/site-packages/keras/engine/functional.py\", line 589, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/home/mohanakrishnan/.pyenv/versions/3.8.12/envs/quotes_for_posts_783/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/mohanakrishnan/.pyenv/versions/3.8.12/envs/quotes_for_posts_783/lib/python3.8/site-packages/keras/engine/base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/mohanakrishnan/.pyenv/versions/3.8.12/envs/quotes_for_posts_783/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/mohanakrishnan/.pyenv/versions/3.8.12/envs/quotes_for_posts_783/lib/python3.8/site-packages/keras/layers/core/dense.py\", line 233, in call\n      outputs = self.activation(outputs)\n    File \"/home/mohanakrishnan/.pyenv/versions/3.8.12/envs/quotes_for_posts_783/lib/python3.8/site-packages/keras/activations.py\", line 311, in relu\n      return backend.relu(x, alpha=alpha, max_value=max_value, threshold=threshold)\n    File \"/home/mohanakrishnan/.pyenv/versions/3.8.12/envs/quotes_for_posts_783/lib/python3.8/site-packages/keras/backend.py\", line 4956, in relu\n      x = tf.nn.relu(x)\nNode: 'model_1/dense/Relu'\nMatrix size-incompatible: In[0]: [65,1000], In[1]: [4096,512]\n\t [[{{node model_1/dense/Relu}}]] [Op:__inference_train_function_17352]"
     ]
    }
   ],
   "source": [
    "model = define_Model(vocab_size , max_len)\n",
    "epochs = 5\n",
    "steps = len(train_descriptions)\n",
    "\n",
    "for i in range(epochs):\n",
    "    generator = data_generator(train_descriptions , train_features , tokenizer , max_len)\n",
    "    \n",
    "    model.fit_generator(generator , epochs = 1 , steps_per_epoch = steps , verbose = 1)\n",
    "    \n",
    "    model.save('model_'+ str(i+1) + '.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678dd169",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def word_for_id(integer , tokenizer):\n",
    "    for word,index in tokenizer.word_index.items():\n",
    "        if index == integer:\n",
    "            return word\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "78db3aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_desc(model , tokenizer , photo , max_length):\n",
    "    \n",
    "    input_text = 'startseq'\n",
    "    \n",
    "    for i in range(max_length):\n",
    "        \n",
    "        sequence = tokenizer.texts_to_sequences([input_text])[0]\n",
    "        sequence = pad_sequences([sequence] , maxlen=max_length)\n",
    "        \n",
    "        # predict the next word\n",
    "        next_word_id = model.predict([photo,sequence],verbose = 0)\n",
    "        \n",
    "        # get highest probality word from list of words\n",
    "        next_word_id = np.argmax(next_word_id)\n",
    "        \n",
    "        # get word from id\n",
    "        word = word_for_id(next_word_id , tokenizer)\n",
    "        \n",
    "        if word is None:\n",
    "            break\n",
    "            \n",
    "        # update input text\n",
    "        input_text += ' '+ word\n",
    "        \n",
    "        if word == 'endseq':\n",
    "            break\n",
    "            \n",
    "    return input_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "29e8a71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import corpus_bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8967165b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model , desciptions , photos , tokenizer , max_length):\n",
    "    actual , predicted = list() , list()\n",
    "    \n",
    "    for key , desc_list in desciptions.items():\n",
    "        generated_desc = generate_desc(model , tokenizer , photos[key] , max_length)\n",
    "        \n",
    "        references = [d.split() for d in desc_list]\n",
    "        actual.append(references)\n",
    "        predicted.append(generated_desc.split())\n",
    "    \n",
    "    print('Bleu_Score -1 = %f'%corpus_bleu(actual , predicted , weights=(1,0,0,0)))\n",
    "    \n",
    "    print('Bleu_Score -2 = %f'%corpus_bleu(actual , predicted , weights=(0.5,0.5,0,0)))\n",
    "    \n",
    "    print('Bleu_Score -3 = %f'%corpus_bleu(actual , predicted , weights=(0.33,0.33,0.33,0))) \n",
    "    \n",
    "    print('Bleu_Score -4 = %f'%corpus_bleu(actual , predicted , weights=(0.25,0.25,0.25,0.25)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d590fc24",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
